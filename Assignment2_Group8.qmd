---
title: "Assignment 2 Group 8"
subtitle: "Due at 11:59pm on October 3."
author: Leng Seong Che; Bozhou (Peter) Tan
format: pdf
editor: visual
---

The results are based on the data at 7:30pm on Oct 3rd.

GitHub repo: <https://github.com/petertbz/Assignment-2--727.git>

!! Notice: The data from Google API is changing every second, so our analysis is based on the data we obtained at the time we mention above.

You may work in pairs or individually for this assignment. Make sure you join a group in Canvas if you are working in pairs. Turn in this assignment as an HTML or PDF file to ELMS. Make sure to include the R Markdown or Quarto file that was used to generate it.

```{r}
#| message = FALSE
library(tidyverse)
library(gtrendsR)
library(censusapi)
```

In this assignment, you will pull from APIs to get data from various data sources and use your data wrangling skills to use them all together. You should turn in a report in PDF or HTML format that addresses all of the questions in this assignment, and describes the data that you pulled and analyzed. You do not need to include full introduction and conclusion sections like a full report, but you should make sure to answer the questions in paragraph form, and include all relevant tables and graphics.

Whenever possible, use piping and `dplyr`. Avoid hard-coding any numbers within the report as much as possible.

# Pulling from APIs

## `crime` and `loans`

Our first data source is the Google Trends API. Suppose we are interested in the search trends for `crime` and `loans` in Illinois in the year 2020. We could find this using the following code:

```{r warning=FALSE}
res = gtrends(c("crime", "loans"), 
               geo = "US-IL", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)
plot(res)
```

Answer the following questions for the keywords "crime" and "loans".

-   Find the mean, median and variance of the search hits for the keywords.

```{r warning=FALSE}
# transfer the data into tibble
rest = as_tibble(res$interest_over_time)

# find the mean, median and variance of the search hits
library(dplyr)
library(tidyr)
library(knitr)

descriptive = rest %>% 
  group_by(keyword) %>% 
  summarise(n = n(),
            mean = mean(hits),
            median = median(hits),
            variance = var(hits))
kable(descriptive, caption = "Descriptive Statistics of Keywords")
```

According to Table 1, we can find that the keyword `r descriptive[1,1]` has a mean of `r descriptive[1,3]`, a median of `r descriptive[1,4]` and a variance of `r descriptive[1,5]`. The keyword `r descriptive[2,1]` has a mean of `r descriptive[2,3]`, a median of `r descriptive[2,4]` and a variance of `r descriptive[2,5]`.

-   Which cities (locations) have the highest search frequency for `loans`? Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city.

```{r warning=FALSE}
rescity = as_tibble(res$interest_by_city) %>% 
  pivot_wider(., names_from = keyword, values_from = hits) %>% 
  arrange(., desc(loans))
kable(head(rescity), caption = "Highest Search Frequency for Loans")
```

According to Table 2, `r rescity[1,1]` has the highest search frequency for `loans` with the value of $100$, followed by `r rescity[2,1]` and `r rescity[3,1]`.

-   Is there a relationship between the search intensities between the two keywords we used?

```{r warning=FALSE}
crime = rest %>% 
  filter(keyword == "crime") %>% 
  select(date, hits) %>% 
  rename(., crimehits = hits)

loan = rest %>% 
  filter(keyword == "loans") %>% 
  select(date, hits) %>% 
  rename(., loanshits = hits)

crimloan = left_join(crime, loan, by = "date")
cor.test(crimloan$crimehits, crimloan$loanshits)
```

According to the plot at the beginning, search frequencies for "crime" and "loans" have similar trends at the beginning of 2020, where they both went up and down from January to around February 2020. From March to April, search frequency for "loans" increased drastically from approximately 65 to 100, while search frequency for "crime" decreased before it increased again. In other words, the two keywords have a similar trend between January and February and most time between July 2020 and January 2021. However, from March to June 2020, they seem to have a inverse relationship.

If we use the quantitative method to compute the t-statistic and corresponding p-value, we can see that the p-value is bigger than 0.05, which means there is no statistically significant negative relationship between crime and loans.

```{r warning=FALSE}
cor.test(rescity$crime, rescity$loans)
```

If we investigate the relationship based on the interest by city data, the correlation test result suggests that search frequencies for "crime" and "loans" do not have a statistically correlation. However, lots of data are missing in this dataset, which might affect the reliability of the correlation test result.

## `covid` and `mask`

Repeat the above for keywords related to covid. Make sure you use multiple keywords like we did above. Try several different combinations and think carefully about words that might make sense within this context.

We choose `covid` and `mask` as our keywords for analysis.

```{r warning=FALSE}
res2 = gtrends(c("covid", "mask"), 
               geo = "US-IL", 
               time = "2020-03-01 2021-12-31", 
               low_search_volume = TRUE)
plot(res2)
```

```{r warning=FALSE}
# transfer the data into tibble
rest2 = as_tibble(res2$interest_over_time)

# find the mean, median and variance of the search hits
descriptive2 = rest2 %>% 
  group_by(keyword) %>% 
  summarise(n = n(),
            mean = mean(hits),
            median = median(hits),
            variance = var(hits))
kable(descriptive2, caption = "Descriptive Statistics of Keywords")
```

From the table, we can find that the keyword `r descriptive2[1,1]` has a mean of `r descriptive2[1,3]`, a median of `r descriptive2[1,4]` and a variance of `r descriptive2[1,5]`. The keyword `r descriptive2[2,1]` has a mean of `r descriptive2[2,3]`, a median of `r descriptive2[2,4]` and a variance of `r descriptive2[2,5]`.

```{r warning=FALSE}
rescity2 = as_tibble(res2$interest_by_city) %>% 
  pivot_wider(., names_from = keyword, values_from = hits) %>% 
  arrange(., desc(covid))
kable(head(rescity2), caption = "Highest Search Frequency for covid")
```

From the table, we can see that `r rescity2[1,1]` has the highest search frequency for `covid` with the value of $100$, followed by `r rescity2[2,1]` and `r rescity2[3,1]`.

```{r warning=FALSE}
mask = rest2 %>% 
  filter(keyword == "mask") %>% 
  select(date, hits) %>% 
  rename(., maskhits = hits)

covid = rest2 %>% 
  filter(keyword == "covid") %>% 
  select(date, hits) %>% 
  rename(., covidhits = hits)

maskcovid = left_join(mask, covid, by = "date")
cor.test(maskcovid$maskhits, maskcovid$covidhits)
```

From the correlation test, we can see that `covid` has a significantly positive correlation with `mask` at 0.05 level. The correlation probably means that people will search for mask when Covid-19 is severe in one place.

```{r}
cor.test(rescity2$covid, rescity2$mask)
```

If we investigate the relationship based on the interest by city data, the correlation test result suggests significantly positive relationship between search frequencies for covid and mask at 0.05 significance level.

## `covid` and `vaccine`

We choose `covid` and `vaccine` as our keywords for analysis.

```{r warning=FALSE}
res3 = gtrends(c("covid", "vaccine"), 
               geo = "US-IL", 
               time = "2020-03-11 2021-3-11", 
               low_search_volume = TRUE)
plot(res3)
```

```{r warning=FALSE}
# transfer the data into tibble
rest3 = as_tibble(res3$interest_over_time)

# find the mean, median and variance of the search hits
descriptive3 = rest3 %>% 
  group_by(keyword) %>% 
  summarise(n = n(),
            mean = mean(hits),
            median = median(hits),
            variance = var(hits))
kable(descriptive3, caption = "Descriptive Statistics of Keywords")
```

From the table, we can find that the keyword `r descriptive3[1,1]` has a mean of `r descriptive3[1,3]`, a median of `r descriptive3[1,4]` and a variance of `r descriptive3[1,5]`. The keyword `r descriptive3[2,1]` has a mean of `r descriptive3[2,3]`, a median of `r descriptive3[2,4]` and a variance of `r descriptive3[2,5]`.

```{r warning=FALSE}
rescity3 = as_tibble(res3$interest_by_city) %>% 
  pivot_wider(., names_from = keyword, values_from = hits) %>% 
  arrange(., desc(vaccine))
kable(head(rescity3), caption = "Highest Search Frequency for vaccine")
```

From the table, we can see that `r rescity3[1,1]` has the highest search frequency for `vaccine` with the value of $100$, followed by `r rescity3[2,1]` and `r rescity3[3,1]`.

```{r warning=FALSE}
vaccine = rest3 %>% 
  filter(keyword == "vaccine") %>% 
  select(date, hits) %>% 
  rename(., vaccinehits = hits)

covid = rest3 %>% 
  filter(keyword == "covid") %>% 
  select(date, hits) %>% 
  rename(., covidhits = hits)

vaccinecovid = left_join(vaccine, covid, by = "date")
cor.test(vaccinecovid$vaccinehits, vaccinecovid$covidhits)
```

The search popularities for covid and vaccine seem to have a positive relationship starting from November 2020. As the vaccine became available around this time, the search for vaccine increases drastically and follows a similar pattern of covid.

From the correlation test, we can see that `covid` has a significantly positive correlation with `vaccine` at 0.1 level.

```{r warning=FALSE}
rescity3$covid <- as.numeric(as.character(rescity3[[4]]))
rescity3$vaccine <- as.numeric(as.character(rescity3[[5]]))
cor.test(rescity3$covid, rescity3$vaccine)
```

If we investigate the relationship based on the interest by city data, the correlation test result suggests a significantly positive  relationship between search frequencies for covid and vaccine at 0.05 significance level.

# Google Trends + ACS

## `crime` and `loans`

Now lets add another data set. The `censusapi` package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

<https://api.census.gov/data/key_signup.html>

Once you have an access key, store this key in the `cs_key` object. We will use this object in all following API queries.

```{r warning=FALSE}
cs_key <- "c0fd12402e23b7a95923e694f046015d624c91c5"
```

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois.

```{r warning=FALSE}
acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "place:*", 
                    regionin = "state:17",
                    key = cs_key)
head(acs_il)
```

Convert values that represent missings to NAs.

```{r warning=FALSE}
acs_il[acs_il == -666666666] <- NA
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names.

```{r warning=FALSE}
acs_il <-
  acs_il %>%
  rename(pop = B01001_001E, 
         age = B06002_001E, 
         hh_income = B19013_001E, 
         income = B19301_001E)
```

It seems like we could try to use this location information listed above to merge this data set with the Google Trends data. However, we first have to clean `NAME` so that it has the same structure as `location` in the search interest by city data. Add a new variable `location` to the ACS data that only includes city names.

```{r warning=FALSE}
library(stringr)
pattern = c("St." = "Saint")

acs_il = acs_il %>% 
  mutate(location = str_remove_all(NAME, c(" town,| city,| village,| Illinois"))) %>% 
  mutate(location = str_replace_all(location, coll(pattern)))
```

Answer the following questions with the "crime" and "loans" Google trends data and the ACS data.

-   First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

```{r warning=FALSE}
joint = inner_join(rescity, acs_il, by = "location")
nrow(joint)

# check how many cities do not appear in both datasets
n = (nrow(acs_il) - nrow(joint) ) + (nrow(rescity) - nrow(joint))
n
```

-   Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

```{r warning=FALSE}
group1 = joint %>% 
  mutate(mean = mean(hh_income, na.rm = TRUE)) %>% 
  mutate(group = ifelse(hh_income > mean, "high", "low")) %>% 
  group_by(group) %>% 
  summarise(crime = mean(crime, na.rm = TRUE),
            loans = mean(loans, na.rm = TRUE)) %>% 
  filter(!is.na(group))
kable(group1, caption = "Search Popularity by Household Income")
```

From the table, cities that have an above average median household income have lower crime hits and lower loans hits, which means crime and loans may correlate with income. The reason for higher mean search popularity of "crime" can be that those with lower average median household income live in some neighborhoods with a relatively higher number of crimes. Houses in areas with more crimes can be more affordable. The reason for higher mean search popularity of "loans" can be these households need more loans for various living expenses such as education. Also, the low search popularity might be due to less access to internet for lower-income. 

-   Is there a relationship between the median household income and the search popularity of the Google trends terms? Describe the relationship and use a scatterplot with `qplot()`.

```{r warning=FALSE}
cor.test(joint$hh_income, joint$crime, method = "pearson")
cor.test(joint$hh_income, joint$loans, method = "pearson")

p1 = qplot(x = hh_income, y = crime, data = joint) + 
  geom_point() + 
  geom_smooth(method = lm) +
  labs(
    title = "Scatter Plot of Median Household Income vs. 'crime' Search by City",
    x = "Median Household Income",
    y = "Search Popularity: crime"
  )

p1

p2 = qplot(x = hh_income, y = loans, data = joint) + 
  geom_point() + 
  geom_smooth(method = lm) +
  labs(
    title = "Scatter Plot of Median Household Income vs. 'loans' Search by City",
    x = "Median Household Income",
    y = "Search Popularity: loans"
  )

p2
```

The results from the Pearson correlation test suggest a negative statistically significant correlation between the median household income and the search popularity for "loans" and a statistically non-significant correlation between the median household income and "crime" at 0.05 level. These can also be observed in the scatter plots. For "crime", the majority of the cities have search popularity below 40 regardless of median household income. A slightly decreasing trend according to the the regression line, however, the correlation test suggests an absence of statistically significant relationship between them. For "loans", a decreasing trend is suggested based on the regression line. As the median household income increases, the search popularity for "loans" decrease. For those with median household income higher than \$100,000, the searches are mostly lower than 25. Those median household income higher than lower than \$100,000 have a wider range of search numbers.

## `covid` and `mask`

Repeat the above steps using the covid data and the ACS data.

```{r warning=FALSE}
joint2 = inner_join(rescity2, acs_il, by = "location")

group2 = joint2 %>% 
  mutate(mean = mean(hh_income, na.rm = TRUE)) %>% 
  mutate(group = ifelse(hh_income > mean, "high", "low")) %>% 
  group_by(group) %>% 
  summarise(covid = mean(covid, na.rm = TRUE),
            mask = mean(mask, na.rm = TRUE)) %>% 
  filter(!is.na(group))
kable(group2, caption = "Search Popularity by Household Income")
```

From the table, we can see cities that have an above average median household income have higher covid hits and higher mask hits, which means search hits of covid and mask may correlate with income positively.

```{r warning=FALSE}
cor.test(joint2$hh_income, joint2$covid, method = "pearson")
cor.test(joint2$hh_income, joint2$mask, method = "pearson")

p3 = qplot(x = hh_income, y = covid, data = joint2) + 
  geom_point() + 
  geom_smooth(method = lm) +
  labs(
    title = "Scatter Plot of Median Household Income vs. 'covid' Search by City",
    x = "Median Household Income",
    y = "Search Popularity: covid"
  )

p3

p4 = qplot(x = hh_income, y = mask, data = joint2) + 
  geom_point() + 
  geom_smooth(method = lm) +
  labs(
    title = "Scatter Plot of Median Household Income vs. 'mask' Search by City",
    x = "Median Household Income",
    y = "Search Popularity: mask"
  )

p4
```

According to the scatterplots, we can see that the income is both positively correlated with covid and mask. This indicates that people in rich areas may pay attention to covid and its protection more, showing one kind of social inequality. From the correlation test, we can see that the p-value of both tests are both less than 0.05, indicating that income has a statistically significant positive relation with both covid and mask.

## `covid` and `vaccine`

```{r warning=FALSE}
joint3 = inner_join(rescity3, acs_il, by = "location")

group3 = joint3 %>% 
  mutate(mean = mean(hh_income, na.rm = TRUE)) %>% 
  mutate(group = ifelse(hh_income > mean, "high", "low")) %>% 
  group_by(group) %>% 
  summarise(covid = mean(covid, na.rm = TRUE),
            vaccine = mean(vaccine, na.rm = TRUE)) %>% 
  filter(!is.na(group))
kable(group3, caption = "Search Popularity by Household Income")
```

From the table, we can see cities that have an above average median household income have higher covid hits and higher mask hits, which means search hits of covid and mask may correlate with income positively.

```{r warning=FALSE}
cor.test(joint3$hh_income, joint3$covid, method = "pearson")
cor.test(joint3$hh_income, joint3$vaccine, method = "pearson")

p5 = qplot(x = hh_income, y = covid, data = joint3) + 
  geom_point() + 
  geom_smooth(method = lm) +
  labs(
    title = "Scatter Plot of Median Household Income vs. 'covid' Search by City",
    x = "Median Household Income",
    y = "Search Popularity: covid"
  )

p5

p6 = qplot(x = hh_income, y = vaccine, data = joint3) + 
  geom_point() + 
  geom_smooth(method = lm) +
  labs(
    title = "Scatter Plot of Median Household Income vs. 'vaccine' Search by City",
    x = "Median Household Income",
    y = "Search Popularity: vaccine"
  )

p6
```

The results from the Pearson correlation test suggest a positive statistically significant correlation between the median household income and both keywords "covid" and "vaccine". The scatter plot results are consistent with the correlation tests. For "covid", the majority of the cities with median household income lower than \$10,000 have search popularity centered around 40. They generally have a wider range of search popularity than those with median household income higher than \$10,000. The latter mostly have over 70 searches for "covid". Based on the plot of median household income and "loans", as the median household income increases, the search popularity for "loans" seems to increase as well. About half of the cities with median household income lower than \$125,000 have search popularity below 60, while the majority of those with median household income higher than \$125,000 have search popularity above 60.
